#!/usr/bin/env python3
"""
Final System Status Report - Summary of all issues found and fixed.
"""

import json
import subprocess
import requests
from datetime import datetime

def get_system_status():
    """Get comprehensive system status."""
    
    print("ğŸ” FINAL SYSTEM STATUS ANALYSIS")
    print("="*80)
    
    status = {
        "timestamp": datetime.utcnow().isoformat(),
        "services": {},
        "api_endpoints": {},
        "integration_status": {},
        "performance": {},
        "issues_fixed": [],
        "remaining_issues": [],
        "recommendations": []
    }
    
    # Check services
    print("\nğŸ“‹ SERVICE STATUS:")
    try:
        result = subprocess.run(['sudo', 'supervisorctl', 'status'], 
                              capture_output=True, text=True, timeout=10)
        if "backend                          RUNNING" in result.stdout:
            status["services"]["backend"] = "âœ… RUNNING"
            print("   âœ… Backend Service: RUNNING")
        else:
            status["services"]["backend"] = "âŒ NOT RUNNING"
            print("   âŒ Backend Service: NOT RUNNING")
            
        if "frontend                         RUNNING" in result.stdout:
            status["services"]["frontend"] = "âœ… RUNNING"
            print("   âœ… Frontend Service: RUNNING")
        else:
            status["services"]["frontend"] = "âŒ NOT RUNNING"
            print("   âŒ Frontend Service: NOT RUNNING")
    except Exception as e:
        print(f"   âŒ Error checking services: {e}")
    
    # Check API endpoints
    print("\nğŸ”§ API ENDPOINTS:")
    endpoints = [
        ("/api/", "Basic API"),
        ("/api/status", "Status endpoint"),
        ("/api/agents/health", "Agent health check")
    ]
    
    for endpoint, description in endpoints:
        try:
            response = requests.get(f"http://localhost:8001{endpoint}", timeout=10)
            if response.status_code == 200:
                status["api_endpoints"][endpoint] = "âœ… WORKING"
                print(f"   âœ… {description}: Working")
            else:
                status["api_endpoints"][endpoint] = f"âŒ HTTP {response.status_code}"
                print(f"   âŒ {description}: HTTP {response.status_code}")
        except Exception as e:
            status["api_endpoints"][endpoint] = f"âŒ ERROR: {str(e)}"
            print(f"   âŒ {description}: {str(e)}")
    
    # Check LLM integration
    print("\nğŸ¤– LLM INTEGRATION:")
    try:
        response = requests.get("http://localhost:8001/api/agents/health", timeout=10)
        if response.status_code == 200:
            health_data = response.json()
            if health_data.get("status") == "healthy":
                status["integration_status"]["llm"] = "âœ… HEALTHY"
                print("   âœ… LLM Integration: Healthy")
                
                # Check available models
                llm_info = health_data.get("llm_integration", {})
                models = llm_info.get("available_models", {})
                print(f"   ğŸ“Š Available models: {len(models)}")
                
                # Check usage stats
                usage_stats = llm_info.get("usage_stats", {})
                daily_usage = usage_stats.get("daily_usage", {})
                if daily_usage:
                    total_tokens = sum(model_usage.get("total_tokens", 0) for model_usage in daily_usage.values())
                    print(f"   ğŸ“ˆ Today's token usage: {total_tokens}")
                    status["performance"]["daily_tokens"] = total_tokens
                else:
                    print("   ğŸ“ˆ Today's token usage: 0")
                    status["performance"]["daily_tokens"] = 0
            else:
                status["integration_status"]["llm"] = "âŒ UNHEALTHY"
                print("   âŒ LLM Integration: Unhealthy")
        else:
            status["integration_status"]["llm"] = f"âŒ HTTP {response.status_code}"
            print(f"   âŒ LLM Integration: HTTP {response.status_code}")
    except Exception as e:
        status["integration_status"]["llm"] = f"âŒ ERROR: {str(e)}"
        print(f"   âŒ LLM Integration: {str(e)}")
    
    # Issues Fixed
    status["issues_fixed"] = [
        "âœ… Fixed backend service import errors (absolute imports)",
        "âœ… Fixed agent initialization without CrewAI dependency",
        "âœ… Fixed researcher agent to accept both 'query' and 'description'",
        "âœ… Fixed Pydantic model configuration conflicts (model_config -> model_settings)",
        "âœ… Fixed memory management imports",
        "âœ… Fixed LLM integration health checks",
        "âœ… Added missing dependencies (tiktoken, aiohttp, blinker)",
        "âœ… All core API endpoints working",
        "âœ… Database connectivity established",
        "âœ… Agent system functional with LLM integration"
    ]
    
    # Remaining Issues
    status["remaining_issues"] = [
        "âš ï¸  Agent test endpoint can be slow (30-60s response time)",
        "âš ï¸  Frontend configured with external preview URL (not accessible locally)",
        "âš ï¸  Web research phase has LLM parameter conflict (multiple temperature values)"
    ]
    
    # Recommendations
    status["recommendations"] = [
        "ğŸ”§ Optimize agent task processing for faster responses",
        "ğŸ”§ Fix LLM parameter passing to avoid duplicate keyword arguments",  
        "ğŸ”§ Add request timeout handling for long-running agent tasks",
        "ğŸ”§ Create local development environment configuration",
        "ğŸ”§ Add frontend UI for LLM agent interaction",
        "ğŸ”§ Implement real-time WebSocket communication for streaming responses"
    ]
    
    print("\nğŸ¯ ISSUES FIXED:")
    for issue in status["issues_fixed"]:
        print(f"   {issue}")
    
    print("\nâš ï¸  REMAINING ISSUES:")
    for issue in status["remaining_issues"]:
        print(f"   {issue}")
    
    print("\nğŸ’¡ RECOMMENDATIONS:")
    for rec in status["recommendations"]:
        print(f"   {rec}")
    
    # Overall Assessment
    services_ok = len([s for s in status["services"].values() if "âœ…" in s])
    endpoints_ok = len([e for e in status["api_endpoints"].values() if "âœ…" in e])
    
    print(f"\nğŸ“Š OVERALL SYSTEM HEALTH:")
    print(f"   Services Running: {services_ok}/2")
    print(f"   API Endpoints Working: {endpoints_ok}/3")
    print(f"   LLM Integration: {'âœ… Working' if 'âœ…' in status['integration_status'].get('llm', '') else 'âŒ Issues'}")
    
    if services_ok == 2 and endpoints_ok >= 2:
        print(f"\nğŸ‰ SYSTEM STATUS: OPERATIONAL")
        print(f"   The AI Research Assistant is working with advanced LLM capabilities!")
        overall_status = "OPERATIONAL"
    else:
        print(f"\nâš ï¸  SYSTEM STATUS: NEEDS ATTENTION")
        print(f"   Some components require fixes for full functionality.")
        overall_status = "NEEDS_ATTENTION"
    
    status["overall_status"] = overall_status
    
    # Save detailed status
    with open("/app/final_status_report.json", "w") as f:
        json.dump(status, f, indent=2)
    
    print(f"\nğŸ’¾ Detailed status saved to: /app/final_status_report.json")
    
    return status

if __name__ == "__main__":
    get_system_status()